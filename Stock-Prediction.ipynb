{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Tweepy. Allows access to Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sc9f-18d6b25ff84f00-0e3c8fa56384/.local/lib/python2.7/site-packages\n",
      "Requirement already satisfied: six>=1.7.3 in /usr/local/src/bluemix_jupyter_bundle.v54/notebook/lib/python2.7/site-packages (from tweepy)\n",
      "Requirement already satisfied: requests>=2.4.3 in /usr/local/src/bluemix_jupyter_bundle.v54/notebook/lib/python2.7/site-packages (from tweepy)\n",
      "Requirement already satisfied: requests-oauthlib>=0.4.1 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sc9f-18d6b25ff84f00-0e3c8fa56384/.local/lib/python2.7/site-packages (from tweepy)\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sc9f-18d6b25ff84f00-0e3c8fa56384/.local/lib/python2.7/site-packages (from requests-oauthlib>=0.4.1->tweepy)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Textblob. Used for Natural Language Processing. Goes hand-in-hand with Tweepy for Sentiment Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: textblob in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sc9f-18d6b25ff84f00-0e3c8fa56384/.local/lib/python2.7/site-packages\n",
      "Requirement already up-to-date: nltk>=3.1 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sc9f-18d6b25ff84f00-0e3c8fa56384/.local/lib/python2.7/site-packages (from textblob)\n",
      "Requirement already up-to-date: six in /usr/local/src/bluemix_jupyter_bundle.v54/notebook/lib/python2.7/site-packages (from nltk>=3.1->textblob)\n",
      "[nltk_data] Downloading package brown to /gpfs/fs01/user/sc9f-\n",
      "[nltk_data]     18d6b25ff84f00-0e3c8fa56384/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /gpfs/fs01/user/sc9f-\n",
      "[nltk_data]     18d6b25ff84f00-0e3c8fa56384/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /gpfs/fs01/user/sc9f-\n",
      "[nltk_data]     18d6b25ff84f00-0e3c8fa56384/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /gpfs/fs01/user/sc9f-\n",
      "[nltk_data]     18d6b25ff84f00-0e3c8fa56384/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to /gpfs/fs01/user/sc9f-\n",
      "[nltk_data]     18d6b25ff84f00-0e3c8fa56384/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to /gpfs/fs01/user/sc9f-\n",
      "[nltk_data]     18d6b25ff84f00-0e3c8fa56384/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U textblob\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Requests. HTTP library for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/src/bluemix_jupyter_bundle.v54/notebook/lib/python2.7/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Keras. Built on TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/src/bluemix_jupyter_bundle.v54/notebook/lib/python2.7/site-packages\r\n",
      "Requirement already satisfied: theano in /usr/local/src/bluemix_jupyter_bundle.v54/notebook/lib/python2.7/site-packages (from keras)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/src/bluemix_jupyter_bundle.v54/notebook/lib/python2.7/site-packages (from keras)\r\n",
      "Requirement already satisfied: six in /usr/local/src/bluemix_jupyter_bundle.v54/notebook/lib/python2.7/site-packages (from keras)\r\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/src/bluemix_jupyter_bundle.v54/notebook/lib/python2.7/site-packages (from theano->keras)\r\n",
      "Requirement already satisfied: scipy>=0.11 in /usr/local/src/bluemix_jupyter_bundle.v54/notebook/lib/python2.7/site-packages (from theano->keras)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tweepy\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to Twitter. Requires you to enter consumer_key, consumer_secret, access_token, and access_token_secret. All can be accessed through [dev.twitter.com](https://dev.twitter.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "user = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a temporary CSV file to hold our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Where the csv file will live\n",
    "data = 'data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stock_sentiment(quote, num_tweets):\n",
    "    # Checks if the sentiment for our quote is\n",
    "    # positive or negative, returns True if\n",
    "    # majority of valid tweets have positive sentiment\n",
    "    list_of_tweets = user.search(quote, count=num_tweets)\n",
    "    positive, null = 0, 0\n",
    "\n",
    "    for tweet in list_of_tweets:\n",
    "        blob = TextBlob(tweet.text).sentiment\n",
    "        if blob.subjectivity == 0:\n",
    "            null += 1\n",
    "            next\n",
    "        if blob.polarity > 0:\n",
    "            positive += 1\n",
    "\n",
    "    if positive > ((num_tweets - null)/2):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(stock):\n",
    "    # Download our file from google finance\n",
    "    url = 'http://www.google.com/finance/historical?q=NASDAQ%3A'+stock+'&output=csv'\n",
    "    r = requests.get(url, stream=True)\n",
    "\n",
    "    if r.status_code != 400:\n",
    "        with open(data, 'wb') as f:\n",
    "            for chunk in r:\n",
    "                f.write(chunk)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stock_prediction(stock):\n",
    "\n",
    "    # Collect data points from csv\n",
    "    dataset = []\n",
    "\n",
    "    with open(data) as f:\n",
    "        for n, line in enumerate(f):\n",
    "            if n != 0:\n",
    "                dataset.append(float(line.split(',')[1]))\n",
    "\n",
    "    dataset = np.array(dataset)\n",
    "\n",
    "    # Create dataset matrix (X=t and Y=t+1)\n",
    "    def create_dataset(dataset):\n",
    "        dataX = [dataset[n+1] for n in range(len(dataset)-2)]\n",
    "        return np.array(dataX), dataset[2:]\n",
    "        \n",
    "    trainX, trainY = create_dataset(dataset)\n",
    "\n",
    "    # Create and fit Multilinear Perceptron model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=1, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(trainX, trainY, epochs=200, batch_size=2, verbose=0)\n",
    "\n",
    "    # Our prediction for tomorrow\n",
    "    prediction = model.predict(np.array([dataset[0]]))\n",
    "    #result = '%s stock price will move from %s to %s' % (stock, dataset[0], prediction[0][0])\n",
    "    result = \"%s's stock price will move from %s to %s on the next open day of the stock exchange.\" % (stock, dataset[0], prediction[0][0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a stock quote from NASDAQ (e.g: AAPL, FB, GOOGL): AAPL\n"
     ]
    }
   ],
   "source": [
    "# Ask user for a stock quote\n",
    "stock = raw_input('Enter a stock quote from NASDAQ (e.g: AAPL, FB, GOOGL): ').upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many tweets should I look through to determine the sentiment about AAPL? 35\n"
     ]
    }
   ],
   "source": [
    "num_tweets = int(input('How many tweets should I look through to determine the sentiment about %s? ' % (stock)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data(stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment check of the stock being analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This stock has bad sentiment on Twitter.\n"
     ]
    }
   ],
   "source": [
    "if stock_sentiment(stock, num_tweets):\n",
    "    print 'This stock has good sentiment on Twitter.'\n",
    "    \n",
    "if not stock_sentiment(stock, num_tweets):\n",
    "    print 'This stock has bad sentiment on Twitter.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL's stock price will move from 149.89 to 149.538 on the next open day of the stock exchange.\n"
     ]
    }
   ],
   "source": [
    "# We have our file so we create the neural net and get the prediction\n",
    "print stock_prediction(stock)\n",
    "\n",
    "# We are done so we delete the csv file\n",
    "os.remove(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.0",
   "language": "python",
   "name": "python2-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
